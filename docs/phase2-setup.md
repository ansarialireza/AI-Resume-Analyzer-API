Here's the comprehensive Phase 2 markdown file:

```markdown
# Phase 2: Environment Setup & Foundation

**Status:** ğŸ”„ **In Progress**  
**Timeline:** Week 2  
**Primary Owner:** DevOps Engineer  
**Prerequisites:** Phase 1 Completion âœ…

---

## ğŸ¯ Phase Objective

Establish a robust development environment, configure all external services, and set up the project foundation for seamless development and future deployment.

---

## ğŸ“‹ Phase Deliverables

- [ ] Project repository initialized with proper structure
- [ ] Development environment configured locally
- [ ] Docker containerization working
- [ ] All external services connected and tested
- [ ] CI/CD pipeline foundation established
- [ ] Basic project dependencies installed and configured

---

## ğŸ—ï¸ Project Structure

```
ai-resume-analyzer/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”‚   â”œâ”€â”€ database.py             # Database connection and setup
â”‚   â”‚   â”œâ”€â”€ models.py               # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas.py              # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ dependencies.py         # FastAPI dependencies
â”‚   â”‚   â”œâ”€â”€ ğŸ“ api/                 # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ history.py
â”‚   â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ services/            # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ file_service.py
â”‚   â”‚   â”‚   â””â”€â”€ llm_service.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ core/               # Core utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py        # JWT and password hashing
â”‚   â”‚   â”‚   â”œâ”€â”€ celery_app.py      # Celery configuration
â”‚   â”‚   â”‚   â””â”€â”€ redis_client.py
â”‚   â”‚   â””â”€â”€ ğŸ“ workers/            # Celery tasks
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ tasks.py           # Background tasks
â”œâ”€â”€ ğŸ“ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_api/
â”‚   â”œâ”€â”€ test_services/
â”‚   â””â”€â”€ test_workers/
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”œâ”€â”€ phase1-design.md
â”‚   â”œâ”€â”€ phase2-setup.md           # This file
â”‚   â””â”€â”€ api-reference.md
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â”œâ”€â”€ setup_env.sh
â”‚   â”œâ”€â”€ run_tests.sh
â”‚   â””â”€â”€ deploy.sh
â”œâ”€â”€ ğŸ“ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ Dockerfile.celery
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ ğŸ“ config/
â”‚   â”œâ”€â”€ development.env
â”‚   â”œâ”€â”€ production.env
â”‚   â””â”€â”€ prompts.yaml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ”§ Development Environment Setup

### 2.1 Prerequisites Installation

#### System Requirements
- **Python:** 3.11 or higher
- **Docker & Docker Compose**
- **Git**
- **Redis** (or use Docker version)

#### Python Environment Setup
```bash
# Clone repository
git clone https://github.com/your-org/ai-resume-analyzer.git
cd ai-resume-analyzer

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt  # Development dependencies
```

### 2.2 Configuration Files

#### Environment Variables (`.env`)
```bash
# Application
APP_NAME="AI Resume Analyzer"
APP_ENV=development
DEBUG=true
SECRET_KEY=your-super-secret-key-here

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/resume_analyzer

# Redis
REDIS_URL=redis://localhost:6379/0

# Gemini AI
GEMINI_API_KEY=your-gemini-api-key-here

# Security
JWT_SECRET_KEY=your-jwt-secret-key
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=60
JWT_REFRESH_EXPIRE_DAYS=7

# Rate Limiting
RATE_LIMIT_PER_MINUTE=5
```

#### Prompts Configuration (`config/prompts.yaml`)
```yaml
resume_analysis_en: |
  You are an expert resume analyst. Analyze the following resume and job description. 
  Extract skills, calculate a compatibility score (0-100) based on 40% keyword match 
  and 60% semantic similarity, identify missing skills, and provide 3 actionable 
  improvement suggestions. Output MUST be a valid JSON matching the specified schema.

resume_analysis_fa: |
  Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ ØªØ­Ù„ÛŒÙ„ Ø±Ø²ÙˆÙ…Ù‡ Ù‡Ø³ØªÛŒØ¯. Ø±Ø²ÙˆÙ…Ù‡ Ùˆ Ø´Ø±Ø­ Ø´ØºÙ„ Ø²ÛŒØ± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.
  Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯ØŒ Ø§Ù…ØªÛŒØ§Ø² Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ (Û°-Û±Û°Û°) Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒØ¯...
  Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ ÛŒÚ© JSON Ù…Ø¹ØªØ¨Ø± Ø¨Ø§Ø´Ø¯.

language_detection: |
  Detect the primary language of the following text. 
  Return only the language code (e.g., 'en', 'fa', 'ar').
```

---

## ğŸ³ Docker Configuration

### 2.3 Docker Setup

#### Dockerfile
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY src/ ./src/
COPY config/ ./config/

# Expose port
EXPOSE 8000

# Start application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

#### Docker Compose (`docker-compose.yml`)
```yaml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/resume_analyzer
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - ./src:/app/src
      - ./config:/app/config
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  celery-worker:
    build: 
      context: .
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/resume_analyzer
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - ./src:/app/src
      - ./config:/app/config
    command: celery -A app.core.celery_app worker --loglevel=info

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=resume_analyzer
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:
```

---

## ğŸ”— External Services Configuration

### 2.4 Service Connections

#### Google Gemini API Setup
1. **Access Google AI Studio:** https://aistudio.google.com/
2. **Create API Key:** Generate new API key in credentials section
3. **Test Connection:**
```python
import google.generativeai as genai

genai.configure(api_key="your-api-key")
model = genai.GenerativeModel('gemini-pro')
response = model.generate_content("Hello")
print(response.text)
```

#### Supabase Database Setup
1. **Create Project:** https://supabase.com
2. **Get Connection String:** Settings â†’ Database â†’ Connection string
3. **Initial Schema:** Run initial migration to create tables
4. **Enable Row Level Security (RLS):** Configure for multi-tenant security

#### Redis Setup
1. **Local Installation:** `docker run -d -p 6379:6379 redis:7-alpine`
2. **Cloud Alternative:** Redis Cloud or Railway Redis
3. **Test Connection:**
```python
import redis
r = redis.Redis(host='localhost', port=6379, db=0)
r.ping()  # Should return True
```

---

## ğŸ“¦ Dependencies Management

### 2.5 Requirements Files

#### `requirements.txt`
```text
fastapi==0.104.1
uvicorn[standard]==0.24.0
celery==5.3.4
redis==5.0.1
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
alembic==1.12.1
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-dotenv==1.0.0
google-generativeai==0.3.2
pdfplumber==0.10.3
python-docx==1.1.0
langdetect==1.0.9
pydantic==2.5.0
pydantic-settings==2.1.0
```

#### `requirements-dev.txt`
```text
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
black==23.11.0
isort==5.13.2
flake8==6.1.0
mypy==1.7.1
pre-commit==3.5.0
locust==2.20.1
httpx==0.25.2
```

---

## ğŸ”„ CI/CD Pipeline Foundation

### 2.6 GitHub Actions Setup

#### `.github/workflows/ci.yml`
```yaml
name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: user
          POSTGRES_PASSWORD: password
          POSTGRES_DB: resume_analyzer
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run tests
      run: |
        pytest --cov=src --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

---

## ğŸ§ª Verification & Testing

### 2.7 Setup Verification Script

#### `scripts/verify_setup.py`
```python
#!/usr/bin/env python3
"""
Setup verification script for Phase 2 completion
"""

import os
import sys
import asyncio
from pathlib import Path

def check_environment():
    """Verify all environment variables are set"""
    required_vars = [
        'DATABASE_URL',
        'REDIS_URL', 
        'GEMINI_API_KEY',
        'SECRET_KEY'
    ]
    
    missing = [var for var in required_vars if not os.getenv(var)]
    if missing:
        print(f"âŒ Missing environment variables: {missing}")
        return False
    
    print("âœ… All environment variables are set")
    return True

def check_dependencies():
    """Verify all required packages are installed"""
    try:
        import fastapi
        import celery
        import sqlalchemy
        import google.generativeai
        print("âœ… All dependencies are installed")
        return True
    except ImportError as e:
        print(f"âŒ Missing dependency: {e}")
        return False

def check_docker():
    """Verify Docker is running and containers can be started"""
    try:
        import docker
        client = docker.from_env()
        client.ping()
        print("âœ… Docker is running")
        return True
    except Exception as e:
        print(f"âŒ Docker check failed: {e}")
        return False

async def main():
    print("ğŸ” Verifying Phase 2 Setup...")
    print("-" * 40)
    
    checks = [
        check_environment(),
        check_dependencies(),
        check_docker()
    ]
    
    if all(checks):
        print("-" * 40)
        print("ğŸ‰ Phase 2 setup verification PASSED!")
        print("â¡ï¸ Proceed to Phase 3: Core Development")
        return 0
    else:
        print("-" * 40)
        print("âŒ Phase 2 setup verification FAILED!")
        print("Please fix the issues above before proceeding.")
        return 1

if __name__ == "__main__":
    exit(asyncio.run(main()))
```

---

## ğŸš€ Current Tasks

### 2.8 Immediate Action Items

| Task | Owner | Status | Due Date |
|------|-------|--------|----------|
| Initialize Git repository | @dev1 | âœ… Done | 2024-01-16 |
| Set up Python virtual environment | @dev1 | ğŸ”„ In Progress | 2024-01-17 |
| Configure Docker and docker-compose | @ops1 | â³ Pending | 2024-01-18 |
| Set up Supabase database | @dev1 | â³ Pending | 2024-01-19 |
| Configure Gemini API access | @ai1 | â³ Pending | 2024-01-19 |
| Create basic project structure | @dev1 | â³ Pending | 2024-01-20 |
| Set up CI/CD pipeline | @ops1 | â³ Pending | 2024-01-22 |

---

## ğŸ“ Next Steps

### Completion Criteria
- [ ] All Docker containers start without errors
- [ ] Database connection established and migrations can run
- [ ] Redis connection working for Celery tasks
- [ ] Gemini API can be called successfully
- [ ] Basic FastAPI server starts and responds to requests
- [ ] CI pipeline passes all initial checks

### Ready for Phase 3 When:
1. âœ… Development environment is fully functional
2. âœ… All external services are connected and tested
3. âœ… Project structure follows established patterns
4. âœ… Team can run the application locally

---

## ğŸ”— Related Documents

- [â† Back to Main Project Hub](../MAIN.md)
- [â†’ Proceed to Phase 3: Core Development](./phase3-development.md)
- [â† Review Phase 1: Planning & Design](./phase1-design.md)

---
